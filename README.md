# realtime-fraud-pipeline

---

# ğŸš€ Pipeline de DÃ©tection de Fraude en Temps RÃ©el

## ğŸ“Œ Vue dâ€™ensemble

Ce projet met en Å“uvre un **pipeline de dÃ©tection de fraude en temps rÃ©el** en utilisant des technologies modernes de Data Engineering et de Machine Learning.

Le systÃ¨me simule des transactions financiÃ¨res, les traite en temps rÃ©el via **Apache Kafka et Spark Structured Streaming**, applique un **modÃ¨le de Machine Learning pour le scoring de fraude**, stocke les donnÃ©es enrichies dans **PostgreSQL**, puis visualise les indicateurs via un **dashboard Streamlit**.

Ce projet dÃ©montre :

* Lâ€™ingestion de donnÃ©es en temps rÃ©el
* Le traitement distribuÃ© de flux (stream processing)
* Lâ€™industrialisation dâ€™un modÃ¨le ML
* Une architecture orientÃ©e production
* Lâ€™aide Ã  la dÃ©cision dans un contexte mÃ©tier

---

## ğŸ— Architecture

```
Producteur (Python)
        â†“
Kafka (streaming d'Ã©vÃ©nements)
        â†“
Spark Structured Streaming
        â†“
ModÃ¨le ML (Scoring fraude)
        â†“
PostgreSQL
        â†“
Dashboard Streamlit
```

---

## âš™ï¸ Stack Technique

* **Python**
* **Apache Kafka**
* **Apache Spark 3.5 (Structured Streaming + MLlib)**
* **PostgreSQL**
* **Docker / Docker Compose**
* **Streamlit**

---

## ğŸ¯ Fonctionnement du Projet

### 1ï¸âƒ£ Simulation des Transactions

Un producteur Python gÃ©nÃ¨re des transactions synthÃ©tiques comprenant :

* montant
* commerÃ§ant
* pays
* timestamp
* identifiant client

Ces transactions sont envoyÃ©es en temps rÃ©el dans Kafka.

---

### 2ï¸âƒ£ Traitement en Temps RÃ©el

Spark lit les transactions depuis Kafka et :

* Parse les messages JSON
* Applique du feature engineering
* Charge un modÃ¨le ML entraÃ®nÃ©
* Calcule un score de risque
* Classe la transaction comme frauduleuse ou non

---

### 3ï¸âƒ£ Stockage des DonnÃ©es

Les rÃ©sultats sont enregistrÃ©s dans PostgreSQL :

* `transactions_enriched`
* `fraud_alerts`

---

### 4ï¸âƒ£ Visualisation & Monitoring

Le dashboard Streamlit permet de visualiser :

* Le taux de fraude
* Les transactions Ã  haut risque
* La distribution des scores
* Lâ€™activitÃ© rÃ©cente

---

# ğŸš€ Lancer le Projet (Ã‰tapes)

## 1ï¸âƒ£ DÃ©marrer lâ€™infrastructure Docker

```bash
docker compose up -d
```

VÃ©rifier que les conteneurs tournent :

```bash
docker ps
```

---

## 2ï¸âƒ£ CrÃ©er le Topic Kafka

```bash
docker exec -it realtime-fraud-pipeline-kafka-1 bash -lc \
"kafka-topics --bootstrap-server kafka:29092 --create \
--topic transactions --partitions 1 --replication-factor 1 || true"
```

---

## 3ï¸âƒ£ EntraÃ®ner le ModÃ¨le ML

```bash
docker exec -it realtime-fraud-pipeline-spark-1 bash -lc \
"/opt/spark/bin/spark-submit --master local[*] /opt/streaming/train_model.py"
```

Cela gÃ©nÃ¨re le modÃ¨le dans :

```
/opt/streaming/model
```

---

## 4ï¸âƒ£ Lancer le Streaming

```bash
docker exec -it realtime-fraud-pipeline-spark-1 bash -lc \
"/opt/spark/bin/spark-submit --master local[*] /opt/streaming/spark_job.py"
```

Laisser ce terminal ouvert.

---

## 5ï¸âƒ£ Lancer le Producteur

```bash
python src/producer/producer.py
```

---

## 6ï¸âƒ£ Ouvrir le Dashboard

```
http://localhost:8501
```

---

# ğŸ“Š Prise de DÃ©cision dans un Cadre MÃ©tier

Ce projet permet de soutenir des dÃ©cisions opÃ©rationnelles en temps rÃ©el dans un environnement financier.

---

## ğŸ” 1. Blocage des Transactions Ã  Risque

Si :

```
risk_score > seuil
```

Alors :

* Blocage automatique de la transaction
* Mise en revue manuelle
* DÃ©clenchement dâ€™une alerte

---

## ğŸ“ˆ 2. Surveillance Dynamique du Risque

Le dashboard permet dâ€™identifier :

* Lâ€™Ã©volution du taux de fraude
* Les commerÃ§ants Ã  risque
* Les pays suspects
* Les clients Ã  forte exposition

Cela permet :

* De prioriser les enquÃªtes
* Dâ€™ajuster les seuils de risque
* Dâ€™optimiser les ressources antifraude

---

## ğŸ’° 3. Optimisation FinanciÃ¨re

La fraude implique un arbitrage :

| Trop strict                  | Trop permissif       |
| ---------------------------- | -------------------- |
| Blocage de clients lÃ©gitimes | Pertes financiÃ¨res   |
| Insatisfaction client        | Risque rÃ©glementaire |

Les Ã©quipes mÃ©tiers peuvent :

* Ajuster le seuil de fraude
* Optimiser prÃ©cision vs rappel
* Minimiser le coÃ»t des faux positifs

---

# ğŸ§  ModÃ¨le Machine Learning

ModÃ¨le utilisÃ© :

* **RÃ©gression Logistique (Spark MLlib)**

Variables utilisÃ©es :

* Montant
* Pays
* CommerÃ§ant
* CatÃ©gorie
* Encodage des variables catÃ©gorielles

Sortie :

```
risk_score âˆˆ [0,1]
```

---

# ğŸ”„ AmÃ©liorations Futures

* DÃ©tection de dÃ©rive du modÃ¨le (data drift)
* Monitoring avancÃ©
* Microservices pour le scoring
* Remplacement par :

  * Gradient Boosted Trees
  * XGBoost
  * Deep Learning
* DÃ©ploiement Cloud (AWS / GCP)
* Gestion des erreurs via Kafka Dead Letter Queue

---

# ğŸ“Œ Ce que DÃ©montre ce Projet

* Un pipeline temps rÃ©el complet
* Lâ€™industrialisation dâ€™un modÃ¨le ML
* Une architecture orientÃ©e production
* Une logique dÃ©cisionnelle mÃ©tier
* Une approche Data Engineering avancÃ©e

